{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ad8250d-e92a-4e38-bc85-2772140046cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32047790-5b1b-4a85-980b-f78aa9b51f07",
   "metadata": {},
   "source": [
    "## Necessary Classes for GPT Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edc4b41-0a3c-4375-beec-cb7155be366a",
   "metadata": {},
   "source": [
    "### Multi-Head Attention Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a2d3a7c-7b8b-403b-bb75-89c7c5b73228",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \\\n",
    "            \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length),\n",
    "                       diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
    "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim) \n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
    "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
    "\n",
    "        # Original mask truncated to the number of tokens and converted to boolean\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        # Use the mask to fill attention scores\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        \n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2) \n",
    "        \n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec) # optional projection\n",
    "\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebde8b25-0b56-462d-97b4-3f70067004f6",
   "metadata": {},
   "source": [
    "### Layer Normalization, GELU and Feed-Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6a8f3fb-cf19-4781-a90d-4a756d030b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n",
    "        \n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0/torch.pi)) *\n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]), # Expansion\n",
    "            GELU(), # Activation\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]) # Contraction\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc75817-1b96-4a85-b1fe-95c8db82ea3e",
   "metadata": {},
   "source": [
    "### Transformer Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff260f6c-ba56-427b-883c-a222a4fed989",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg['emb_dim'], \n",
    "            d_out=cfg['emb_dim'], \n",
    "            context_length=cfg['context_length'], \n",
    "            num_heads=cfg['n-heads'], \n",
    "            dropout=cfg['drop_rate'], \n",
    "            qkv_bias=cfg['qkv_bias'])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg['emb_dim'])\n",
    "        self.norm2 = LayerNorm(cfg['emb_dim'])\n",
    "        self.drop_shortcut = nn.Dropout(cfg['drop_rate'])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Shortcut connection for attention block\n",
    "        shortcut = x # Shortcut connection for attention block\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "        \n",
    "        # Shortcut connection for feedforward block\n",
    "        shortcut = x # Shortcut connection for attention block\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd86cc28-afe5-4ca2-9e1b-720ef6ed1d8d",
   "metadata": {},
   "source": [
    "### GPT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a40095ed-b1e7-4253-9578-182b88c51d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        # Use a placeholder for TransformerBlock\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        \n",
    "        # Use a placeholder for LayerNorm\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fda9d92-f2cd-44c2-88a3-dc4b274a2fb9",
   "metadata": {},
   "source": [
    "### Generating Text from Output Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59b14656-d6ba-444f-ac15-a6e1401a7d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    # idx is (batch, n_tokens) array of indices in the current context\n",
    "    for _ in range(max_new_tokens):\n",
    "        \n",
    "        # Crop current context if it exceeds the supported context size\n",
    "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
    "        # then only the last 5 tokens are used as context\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        \n",
    "        # Get the predictions\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        \n",
    "        # Focus only on the last timestamp\n",
    "        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
    "        logits = logits[:, -1, :]  \n",
    "\n",
    "        # Apply softmax to get probabilities\n",
    "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
    "\n",
    "        # Get the idx of the vocab entry with the highest probability value\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
    "\n",
    "        # Append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70de9a1-47ae-4587-b137-e1a07539a9fb",
   "metadata": {},
   "source": [
    "### Dataset and DataLoader Classess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "456a52d2-63cf-447a-806e-b39a9a6f7337",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={'<|endoftext|>'})\n",
    "        \n",
    "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i: i+max_length]\n",
    "            target_chunk = token_ids[i+1: i+max_length+1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e972179-1075-4597-96a7-b7a5db1f392f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
    "    \n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    \n",
    "    # Create dataset\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68420021-2a96-4d10-bfeb-eb9b71f6c04d",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef2d35d0-da16-4891-8c2e-0765c798eb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # Add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # Remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8028564-4a6c-4c36-943f-1e3c849fccee",
   "metadata": {},
   "source": [
    "## Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a73827d5-3b2f-4241-b250-98786107d560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to calculate the cross-entropy loss of a given batch\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0,1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb7af89-7678-4e70-b281-17bbf359f87a",
   "metadata": {},
   "source": [
    "## Training Loop for LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b289afaa-9af4-49d6-a370-5c32ba77ecb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "# Open the file in read mode\n",
    "with open('harry_potter_all.txt', 'r', encoding=\"utf-8\") as file:\n",
    "    # Read the contents of the file\n",
    "    text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "90614e5d-b9ea-4c4f-b38c-8f39386a6668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE BOY WHO LIVED\n",
      "Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say\n",
      "that they w\n",
      "pying,\n",
      "recording, or otherwise, without written permission of the publisher.\n",
      "ISBN 978-1-78110-647-1\n"
     ]
    }
   ],
   "source": [
    "# First 100 characters\n",
    "print(text_data[:99])\n",
    "\n",
    "# Last 100 characters\n",
    "print(text_data[-99:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1e165dfe-5c95-4b04-a91b-cd24d88c48f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 6,271,892\n",
      "Tokens:1,786,866\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data) \n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(f'Characters: {total_characters:,}')\n",
    "print(f\"Tokens:{total_tokens:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d2da7187-7a1d-470f-8566-f326846becbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Validation Ratio\n",
    "train_ratio = 0.9\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M['context_length'],\n",
    "    stride=GPT_CONFIG_124M['context_length'],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M['context_length'],\n",
    "    stride=GPT_CONFIG_124M['context_length'],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "932887b2-89f6-438f-834a-ef7f5d192266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Check\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the training loader. Try to lower the  GPT_CONFIG_124M['context_length'] or increase the training ratio\")\n",
    "\n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the validation loader. Try to lower the  GPT_CONFIG_124M['context_length'] or decrease the training ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c24b014f-80ae-479e-93a3-a18aa507c10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loader:\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "\n",
      "Validation Loader:\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
      "785\n",
      "87\n"
     ]
    }
   ],
   "source": [
    "# Optional check that the data is loaded correctly\n",
    "print(\"Train Loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation Loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(len(train_loader))\n",
    "print(len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f8c63c0f-7d87-4028-896c-d432bcb3cc69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Tokens: 1607680\n",
      "Validation Tokens: 177152\n",
      "All Tokens: 1784832\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Training Tokens:\", train_tokens)\n",
    "print(\"Validation Tokens:\", val_tokens)\n",
    "print(\"All Tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4bb6876a-33da-44f7-8efe-f089f8a7b9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9f4299f5-e839-48cb-843d-14fad67bbc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel() # Returns the total number of elements (or tokens) in the input_batch.\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0: \n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "eb8ee69b-446a-41dc-a145-3175b0a8babb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "87c13c94-79ae-4f11-89f9-2bdd622edf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "841fa540-2266-481e-812d-64356f328a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.502, Val loss 9.540\n",
      "Ep 1 (Step 000400): Train loss 4.677, Val loss 4.922\n",
      "Every effort moves you, said Ron,I said Ron, said Ron, said Ron. I said Ron, said Ron, said Ron. I said Ron.\n",
      "Ep 2 (Step 000800): Train loss 4.315, Val loss 4.674\n",
      "Ep 2 (Step 001200): Train loss 4.100, Val loss 4.552\n",
      "Every effort moves you, said Ron, Is a the Chosen One. I said Ron, Is a  Imstrang,\n",
      "Ep 3 (Step 001600): Train loss 3.856, Val loss 4.413\n",
      "Ep 3 (Step 002000): Train loss 3.639, Val loss 4.324\n",
      "Every effort moves you, said Harry, Im not to you, Im sure youve got to be able to youre not to youre you, youre not,\n",
      "Ep 4 (Step 002400): Train loss 3.379, Val loss 4.228\n",
      "Ep 4 (Step 002800): Train loss 3.177, Val loss 4.174\n",
      "Every effort moves youre not going to the Ministry. Ill have to ask you, said Harry. Ill have to have you, Ill have to tell you.\n",
      "Ep 5 (Step 003200): Train loss 2.920, Val loss 4.157\n",
      "Ep 5 (Step 003600): Train loss 2.730, Val loss 4.159\n",
      "Every effort moves youre going to do anything like it? Im not going to tell youve been in the  Im not going to tell youve been\n",
      "Ep 6 (Step 004000): Train loss 2.441, Val loss 4.189\n",
      "Ep 6 (Step 004400): Train loss 2.240, Val loss 4.223\n",
      "Every effort moves you, said Harry. Im going to be a bit of a governors, said Ron. Im not going to be able to get to tell us what theyre\n",
      "Ep 7 (Step 004800): Train loss 1.980, Val loss 4.346\n",
      "Ep 7 (Step 005200): Train loss 1.812, Val loss 4.418\n",
      "Every effort moves you were too busy at all. Im not going to be up to be so desperate for a colleague of the rent on the school, said Harry, as he and Ron and Hermione sat\n",
      "Ep 8 (Step 005600): Train loss 1.509, Val loss 4.577\n",
      "Ep 8 (Step 006000): Train loss 1.388, Val loss 4.621\n",
      "Every effort moves you in the way. You know youd be able to find out of this time. Id have thought Id have to go with your parents time, said Harry. I\n",
      "Ep 9 (Step 006400): Train loss 1.131, Val loss 4.797\n",
      "Ep 9 (Step 006800): Train loss 1.059, Val loss 4.869\n",
      "Every effort moves you dreamed this? No volunteers? said Harry. Youre kidding! Yeah . . . . I thought  Yeah, said Harry, \n",
      "Ep 10 (Step 007200): Train loss 0.860, Val loss 5.056\n",
      "Ep 10 (Step 007600): Train loss 0.799, Val loss 5.150\n",
      "Every effort moves you dreamed this, said Bellatrix indifferently. Id like to come out with him so hed cut himself off for so grateful hed be sucked through hes grip and\n",
      "Training completed in 31.38 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context Length\n",
    "    \"emb_dim\": 768,          # Embedding dimension\n",
    "    \"n-heads\": 12,           # Number of attention heads\n",
    "    \"n_layers\": 12,          # Number of Layers\n",
    "    \"drop_rate\": 0.1,        # Dropout rate\n",
    "    \"qkv_bias\": False        # Query-Key-Value bias\n",
    "}\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model_hp = GPTModel(GPT_CONFIG_124M)\n",
    "model_hp.to(device)\n",
    "optimizer = torch.optim.AdamW(model_hp.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model_hp, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=400, eval_iter=400,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Note:\n",
    "# Uncomment the following code to show the execution time\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a31ffa50-c574-40c3-a5e5-b508532f49a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.818, Val loss 9.932\n",
      "Ep 1 (Step 000005): Train loss 8.064, Val loss 8.340\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 6.621, Val loss 7.052\n",
      "Ep 2 (Step 000015): Train loss 6.047, Val loss 6.600\n",
      "Every effort moves you, and,, and,,,,,,, and,.                                   \n",
      "Ep 3 (Step 000020): Train loss 5.583, Val loss 6.479\n",
      "Ep 3 (Step 000025): Train loss 5.540, Val loss 6.408\n",
      "Every effort moves you, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and\n",
      "Ep 4 (Step 000030): Train loss 5.141, Val loss 6.364\n",
      "Ep 4 (Step 000035): Train loss 4.994, Val loss 6.387\n",
      "Every effort moves you a a, and a a, and a-- the picture. Gisburn, and a was, and a. I had been. of the of the of the of the a of the of the of the of the of the of the of\n",
      "Ep 5 (Step 000040): Train loss 4.356, Val loss 6.256\n",
      "Every effort moves you, I had been the picture, I had to the picture. \"Oh, in the picture, in the fact of the picture to me. \"I had been the picture--and it, in the picture--and it's it's\n",
      "Ep 6 (Step 000045): Train loss 4.004, Val loss 6.208\n",
      "Ep 6 (Step 000050): Train loss 3.514, Val loss 6.174\n",
      "Every effort moves you know the \"Oh, and.  \"I had been.             \"Oh, and I had been the donkey.            \n",
      "Ep 7 (Step 000055): Train loss 3.547, Val loss 6.196\n",
      "Ep 7 (Step 000060): Train loss 2.731, Val loss 6.157\n",
      "Every effort moves you know he was to have to the Riviera, I was a little of a little to have to see it.     \"I he was his pictures--I had the picture. I had been the man of the picture. \n",
      "Ep 8 (Step 000065): Train loss 2.292, Val loss 6.143\n",
      "Ep 8 (Step 000070): Train loss 1.946, Val loss 6.211\n",
      "Every effort moves you know,\" was not that the picture.  \"I had the last word. Gisburn's an!   \"I looked up, and I had been at my elbow and I had the donkey. \"There were days, in\n",
      "Ep 9 (Step 000075): Train loss 1.576, Val loss 6.233\n",
      "Ep 9 (Step 000080): Train loss 1.243, Val loss 6.274\n",
      "Every effort moves you know,\" was not that my hostess was \"interesting\": on that I felt to have given Miss Croft the fact, the cigars you like.\"  \"Oh, and his pictures--the quality of Jack's \"There were days when I\n",
      "Ep 10 (Step 000085): Train loss 0.954, Val loss 6.310\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Training completed in 0.34 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 256,  # Context Length\n",
    "    \"emb_dim\": 768,          # Embedding dimension\n",
    "    \"n-heads\": 12,           # Number of attention heads\n",
    "    \"n_layers\": 12,          # Number of Layers\n",
    "    \"drop_rate\": 0.1,        # Dropout rate\n",
    "    \"qkv_bias\": False        # Query-Key-Value bias\n",
    "}\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model_verdict = GPTModel(GPT_CONFIG_124M)\n",
    "model_verdict.to(device)\n",
    "optimizer = torch.optim.AdamW(model_verdict.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model_verdict, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Note:\n",
    "# Uncomment the following code to show the execution time\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a5222c-d67c-4ade-be7e-c867fa950555",
   "metadata": {},
   "source": [
    "### Plot of Training Loss vs Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a8ad8f5d-2f3e-4ed5-8c44-c4d0a1e2a696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAekAAAEiCAYAAADd4SrgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABXHElEQVR4nO3deVxUVf8H8M8sMDPAzLDDIKuIbALigimalqamUWpli4+hLf5KTM0sLXNPzTLzqcyyBXueXNrUx1xTc99wA1EQF0BQQGQd1gFmzu+PCwMjqIDAnYHv+/W6L+eu8z0j8J1z7rnnCBhjDIQQQggxOkK+AyCEEEJIwyhJE0IIIUaKkjQhhBBipChJE0IIIUaKkjQhhBBipChJE0IIIUaKkjQhhBBipChJE0IIIUaKkjQhhBBipChJE0IIIUaKkjQhhBAC4PDhw4iIiICLiwsEAgG2bt3apPMXLFgAgUBQb7G0tGx2TJSkCTEhqampEAgEiI2N5TsUQtqdkpIShISEYPXq1c06f+bMmcjMzDRYAgIC8Pzzzzc7JkrShLSxhr5p110WLFjAd4iEdEhPPvkkPv74Y4wePbrB/RqNBjNnzkSnTp1gaWmJPn364ODBg/r9VlZWcHZ21i+3b99GQkICXnvttWbHJG72mYSQZsnMzNS//vXXXzFv3jwkJSXpt1lZWfERFiHkAaZMmYKEhARs2rQJLi4u2LJlC4YPH474+Hj4+PjUO/6HH35A165dMWDAgGa/J9WkCWljdb9pK5VKCAQC/bqjoyNWrlwJV1dXSCQSdO/eHbt3777ntbRaLV599VX4+fkhLS0NAPC///0PPXr0gFQqRefOnbFw4UJUVVXpzxEIBPjhhx8wevRoWFhYwMfHB9u2bdPvz8/Px7hx4+Dg4ACZTAYfHx9ER0ffM4Y//vgDQUFBkMlksLOzw5AhQ1BSUqLf/8MPP8Df3x9SqRR+fn745ptvDM5PT0/H2LFjYW1tDVtbWzzzzDNITU3V758wYQJGjRqFFStWQKVSwc7ODlFRUaisrGz0Z07Iw0pLS0N0dDR+//13DBgwAN7e3pg5cyb69+/f4O9HeXk51q9f/1C1aAAAI4TwJjo6mimVSv36ypUrmUKhYBs3bmSXL19m77//PjMzM2NXrlxhjDGWkpLCALDz58+z8vJyNnr0aBYaGsqys7MZY4wdPnyYKRQKtm7dOnb9+nX2999/M09PT7ZgwQL9ewBgrq6ubMOGDezq1ats6tSpzMrKiuXm5jLGGIuKimLdu3dnp0+fZikpKWzv3r1s27ZtDcafkZHBxGIxW7lyJUtJSWEXLlxgq1evZkVFRYwxxn755RemUqnYn3/+yZKTk9mff/7JbG1t2bp16xhjjFVUVDB/f3/26quvsgsXLrCEhAT28ssvM19fX6bRaBhjjEVGRjKFQsHefPNNlpiYyP766y9mYWHB1q5d27L/GYTUAYBt2bJFv759+3YGgFlaWhosYrGYjR07tt75GzZsYGKxmGVlZT1cHA91NiHkodydpF1cXNiSJUsMjunduzebPHkyY6w2SR85coQNHjyY9e/fnxUUFOiPHTx4MFu6dKnB+f/973+ZSqXSrwNgH330kX69uLiYAWC7du1ijDEWERHBJk6c2Kj4z549ywCw1NTUBvd7e3uzDRs2GGxbvHgx69u3rz42X19fptPp9Ps1Gg2TyWRsz549jDEuSXt4eLCqqir9Mc8//zx74YUXGhUjIc1xd5LetGkTE4lE7PLly+zq1asGS2ZmZr3zH3/8cTZq1KiHjoPuSRNiJNRqNTIyMhAeHm6wPTw8HHFxcQbbXnrpJbi6uuKff/6BTCbTb4+Li8OxY8ewZMkS/TatVovy8nKUlpbCwsICABAcHKzfb2lpCYVCgezsbADAW2+9hWeffRbnzp3D0KFDMWrUKPTr16/BmENCQjB48GAEBQVh2LBhGDp0KJ577jnY2NigpKQE169fx2uvvYY33nhDf05VVRWUSqU+3mvXrkEulxtct7y8HNevX9evBwYGQiQS6ddVKhXi4+Pv82kS0rJCQ0Oh1WqRnZ39wHvMKSkpOHDggMFtpOaiJE2ICRoxYgR++eUXnDhxAo8//rh+e3FxMRYuXIgxY8bUO0cqlepfm5mZGewTCATQ6XQAuB6uN27cwM6dO7F3714MHjwYUVFRWLFiRb1rikQi7N27F8ePH8fff/+Nr776CnPmzMGpU6f0Xwi+//579OnTp955NfH27NkT69evr3dtBweHRsVLSEspLi7GtWvX9OspKSmIjY2Fra0tunbtinHjxuGVV17B559/jtDQUNy5cwf79+9HcHAwRo4cqT/vp59+gkqlwpNPPvnwQT10XZwQ0myNbe6OiopijBnek/7yyy+ZpaUlO3jwoP7Yfv36sVdfffW+74m7mvEYY0ypVLLo6OgGj//222+ZXC5vVHmqqqpYp06d2Oeff64vz6JFi+55/Nq1a5mNjQ0rLCy85zGRkZHsmWeeMdg2bdo0NnDgwEbFREhjHThwgAGot0RGRjLGuD4U8+bNY56enszMzIypVCo2evRoduHCBf01tFotc3V1ZR9++GGLxEQ1aUKMyHvvvYf58+fD29sb3bt3R3R0NGJjYxusab799tvQarV46qmnsGvXLvTv3x/z5s3DU089BXd3dzz33HMQCoWIi4vDxYsX8fHHHzcqhnnz5qFnz54IDAyERqPB9u3b4e/v3+Cxp06dwv79+zF06FA4Ojri1KlTuHPnjv74hQsXYurUqVAqlRg+fDg0Gg3OnDmD/Px8zJgxA+PGjcNnn32GZ555BosWLYKrqytu3LiBzZs34/3334erq2vzP0xCmmjQoEFgjN1zv5mZGRYuXIiFCxfe8xihUIj09PQWi4mSNCFGZOrUqSgsLMS7776L7OxsBAQEYNu2bQ0+gwkA06dPh06nw4gRI7B7924MGzYM27dvx6JFi7B8+XKYmZnBz88Pr7/+eqNjMDc3xwcffIDU1FTIZDIMGDAAmzZtavBYhUKBw4cPY9WqVVCr1fDw8MDnn3+ub+Z7/fXXYWFhgc8++wzvvfceLC0tERQUhOnTpwMALCwscPjwYcyaNQtjxoxBUVEROnXqhMGDB0OhUDTtwyOkHRKw+31tIIQQQghvaDATQgghxEhRkiaEEEKMFCVpQgghxEhRkiaEEEKMFCVpQgghxEh1uCS9evVqeHp6QiqVok+fPoiJibnv8b///jv8/PwglUoRFBSEnTt3tlGk99eUcnz//fcYMGAAbGxsYGNjgyFDhjyw3G2lqf8fNTZt2gSBQIBRo0a1boCN1NRyFBQUICoqCiqVChKJBF27djWKn62mlmPVqlXw9fWFTCaDm5sb3nnnHZSXl7dRtPUdPnwYERERcHFxgUAgwNatWx94zsGDB9GjRw9IJBJ06dIF69ata/U4G6OpZdm8eTOeeOIJODg4QKFQoG/fvtizZ0/bBHsfzfk/qXHs2DGIxWJ079691eJrrOaUQ6PRYM6cOfDw8IBEIoGnpyd++umnJr1vh0rSv/76K2bMmIH58+fj3LlzCAkJwbBhw/RjFt/t+PHjeOmll/Daa6/h/PnzGDVqFEaNGoWLFy+2ceSGmlqOgwcP4qWXXsKBAwdw4sQJuLm5YejQobh161YbR26oqeWokZqaipkzZz7UHK0tqanlqKiowBNPPIHU1FT88ccfSEpKwvfff49OnTq1ceSGmlqODRs2YPbs2Zg/fz4SExPx448/4tdff8WHH37YxpHXKikpQUhICFavXt2o41NSUjBy5Eg89thjiI2NxfTp0/H6668bRXJralkOHz6MJ554Ajt37sTZs2fx2GOPISIiAufPn2/lSO+vqeWoUVBQgFdeeQWDBw9upciapjnlGDt2LPbv348ff/wRSUlJ2LhxI3x9fZv2xi0ybpmJCAsL0w+vyBg3fJuLiwtbtmxZg8ePHTuWjRw50mBbnz592P/93/+1apwP0tRy3K2qqorJ5XL2888/t1aIjdKcclRVVbF+/fqxH374ocHhIvnQ1HKsWbOGde7cmVVUVLRViI3S1HJERUWxxx9/3GDbjBkzWHh4eKvG2VhoYPjTu73//vssMDDQYNsLL7zAhg0b1oqRNV1jytKQgIAAtnDhwpYPqJmaUo4XXniBffTRR2z+/PksJCSkVeNqqsaUY9euXUypVOqngG2uDlOTrqiowNmzZzFkyBD9NqFQiCFDhuDEiRMNnnPixAmD4wFg2LBh9zy+LTSnHHcrLS1FZWUlbG1tWyvMB2puORYtWgRHR8eHn0i9hTSnHNu2bUPfvn0RFRUFJycndOvWDUuXLoVWq22rsOtpTjn69euHs2fP6pvEk5OTsXPnTowYMaJNYm4Jxvg73lJ0Oh2Kiop4/T1vrujoaCQnJ2P+/Pl8h9Js27ZtQ69evfDpp5+iU6dO6Nq1K2bOnImysrImXafDDAuak5MDrVYLJycng+1OTk64fPlyg+dkZWU1eHxWVlarxfkgzSnH3WbNmgUXF5d6f5zaUnPKcfToUfz444+IjY1tgwgbpznlSE5Oxj///INx48Zh586duHbtGiZPnozKykre/ig1pxwvv/wycnJy0L9/fzDGUFVVhTfffJPX5u6mutfvuFqtRllZmcE0oKZmxYoVKC4uxtixY/kOpUmuXr2K2bNn48iRIxCLTTdFJScn4+jRo5BKpdiyZQtycnIwefJk5ObmIjo6utHX6TA1acL55JNPsGnTJmzZssVg6kJjV1RUhPHjx+P777+Hvb093+E8FJ1OB0dHR6xduxY9e/bECy+8gDlz5uDbb7/lO7QmOXjwIJYuXYpvvvkG586dw+bNm7Fjxw4sXryY79A6vA0bNmDhwoX47bff4OjoyHc4jabVavHyyy9j4cKF6Nq1K9/hPBSdTgeBQID169cjLCwMI0aMwMqVK/Hzzz83qTZtul9Tmsje3h4ikQi3b9822H779m04Ozs3eI6zs3OTjm8LzSlHjRUrVuCTTz7Bvn37EBwc3JphPlBTy3H9+nWkpqYiIiJCv61mPmGxWIykpCR4e3u3btANaM7/h0qlgpmZmX5OZQDw9/dHVlYWKioqYG5u3qoxN6Q55Zg7dy7Gjx+vn7wjKCgIJSUlmDRpEubMmQOh0PjrAPf6HVcoFCZbi960aRNef/11/P7777y2ljVHUVERzpw5g/Pnz2PKlCkAuN9zxhjEYjH+/vtvg/nTjZlKpUKnTp2gVCr12/z9/cEYw82bN+85ac7djP+3qIWYm5ujZ8+e2L9/v36bTqfD/v370bdv3wbP6du3r8HxALB37957Ht8WmlMOAPj000+xePFi7N69G7169WqLUO+rqeXw8/NDfHw8YmNj9cvTTz+t75Xr5ubWluHrNef/Izw8HNeuXdN/yQCAK1euQKVS8ZKggeaVo7S0tF4irvniwUxk3h5j/B1/GBs3bsTEiROxceNGjBw5ku9wmkyhUNT7PX/zzTfh6+uL2NhY9OnTh+8QGy08PBwZGRkoLi7Wb7ty5QqEQmHTpmB9qG5nJmbTpk1MIpGwdevWsYSEBDZp0iRmbW3NsrKyGGOMjR8/ns2ePVt//LFjx5hYLGYrVqxgiYmJbP78+czMzIzFx8fzVQTGWNPL8cknnzBzc3P2xx9/sMzMTP1SVFTEVxEYY00vx92MpXd3U8uRlpbG5HI5mzJlCktKSmLbt29njo6O7OOPP+arCIyxppdj/vz5TC6Xs40bN7Lk5GT2999/M29vbzZ27Fi+isCKiorY+fPn2fnz5xkAtnLlSnb+/Hl248YNxhhjs2fPZuPHj9cfn5yczCwsLNh7773HEhMT2erVq5lIJGK7d+/mqwh6TS3L+vXrmVgsZqtXrzb4PS8oKOCrCIyxppfjbsbSu7up5SgqKmKurq7sueeeY5cuXWKHDh1iPj4+7PXXX2/S+3aoJM0YY1999RVzd3dn5ubmLCwsjJ08eVK/b+DAgSwyMtLg+N9++4117dqVmZubs8DAQLZjx442jrhhTSmHh4cHA1BvmT9/ftsHfpem/n/UZSxJmrGml+P48eOsT58+TCKRsM6dO7MlS5awqqqqNo66vqaUo7Kyki1YsIB5e3szqVTK3Nzc2OTJk1l+fn7bB17twIEDDf6s18QdGRnJBg4cWO+c7t27M3Nzc9a5c2cWHR3d5nE3pKllGThw4H2P50tz/k/qMpYk3ZxyJCYmsiFDhjCZTMZcXV3ZjBkzWGlpaZPel+aTJoQQQoxUh7knTQghhJgaStKEEEKIkaIkTQghhBgpStKEEEKIkaIkTQghhBgpStKEEEKIkaIkTQghhBgpStJ1aDQaLFiwABqNhu9QHgqVw7hQOYwLlcO4UDnujwYzqUOtVkOpVKKwsBAKhYLvcJqNymFcqBzGhcphXKgc90c1aUIIIcRIUZImhBBCjJRJzyddVVWF8+fPw8nJqUXmri0qKgIA3Lp1C2q1+qGvxxcqh3GhchgXKodx6Ujl0Ol0uH37NkJDQyEWNy79mvQ96dOnTyMsLIzvMAghhJBGi4mJQe/evRt1rEnXpJ2cnABwBVapVDxHQwghhNxbZmYmwsLC9LmrMUw6Sdc0catUKri6uvIcDSGEEPJgTbk9Sx3HCCGEECNFSZoQQggxUpSkCSGEECNl0vekCSGkJWi1WlRWVvIdBjFxZmZmEIlELXpNStJ1lFdqUaKpgp2VhO9QCCFtgDGGrKwsFBQU8B0KaSesra3h7OwMgUDQItejJF3tz11/Q35iOVxs5LB7Zyvf4RBC2kBNgnZ0dISFhUWL/WElHQ9jDKWlpcjOzgaAFnssmJJ0NTuFJQYJz6C8UAJoKwGRGd8hEUJakVar1SdoOzs7vsMh7YBMJgMAZGdnw9HRsUWavqnjWLWuAaHIY1aQQoPy9HN8h0MIaWU196AtLCx4joS0JzU/Ty3Vx4GSdDUXGwtcEvoBALIuHuQ3GEJIm6EmbtKSWvrniZJ0HTm2oQAAbepJniMhhJC24+npiVWrVjX6+IMHD0IgELR6h7t169bB2tq6Vd/D2FGSrkPk0RcAYJ9/HjDdeUcIIe2UQCC477JgwYJmXff06dOYNGlSo4/v168fMjMzoVQqm/V+pPGo41gdroH9oDkrhlKbD5aXAoFdZ75DIoQQvczMTP3rX3/9FfPmzUNSUpJ+m5WVlf41YwxarbZRUyI6ODg0KQ5zc3M4Ozs36RzSPFSTriPA3RGXmBcAIC/xMM/REEKIIWdnZ/2iVCohEAj065cvX4ZcLseuXbvQs2dPSCQSHD16FNevX8czzzwDJycnWFlZoXfv3ti3b5/Bde9u7hYIBPjhhx8wevRoWFhYwMfHB9u2bdPvv7u5u6ZZes+ePfD394eVlRWGDx9u8KWiqqoKU6dOhbW1Nezs7DBr1ixERkZi1KhRTfoM1qxZA29vb5ibm8PX1xf//e9/9fsYY1iwYAHc3d0hkUjg4uKCqVOn6vd/88038PHxgVQqhZOTE5577rkmvTcfKEnXITUTIdUyGABQdO0oz9EQQkjTzZ49G5988gkSExMRHByM4uJijBgxAvv378f58+cxfPhwREREIC0t7b7XWbhwIcaOHYsLFy5gxIgRGDduHPLy8u55fGlpKVasWIH//ve/OHz4MNLS0jBz5kz9/uXLl2P9+vWIjo7GsWPHoFarsXXr1iaVbcuWLZg2bRreffddXLx4Ef/3f/+HiRMn4sCBAwCAP//8E1988QW+++47XL16FVu3bkVQUBAA4MyZM5g6dSoWLVqEpKQk7N69G48++miT3p8P1Nx9lwqX3sD1PyHLOsN3KISQNsQYQ1mllpf3lpmJWqxX8KJFi/DEE0/o121tbRESEqJfX7x4MbZs2YJt27ZhypQp97zOhAkT8NJLLwEAli5dii+//BIxMTEYPnx4g8dXVlbi22+/hbe3NwBgypQpWLRokX7/V199hQ8++ACjR48GAHz99dfYuXNnk8q2YsUKTJgwAZMnTwYAzJgxAydPnsSKFSvw2GOPIS0tDc7OzhgyZAjMzMzg7u6OsLAwAEBaWhosLS3x1FNPQS6Xw8PDA6GhoU16fz5Qkr6Lte8A4DrgVJ4ClOUDMhu+QyKEtIGySi0C5u3h5b0TFg2DhXnL/Dnu1auXwXpxcTEWLFiAHTt2IDMzE1VVVSgrK3tgTTo4OFj/2tLSEgqFQj+aVkMsLCz0CRrgRtyqOb6wsBC3b9/WJ0wAEIlE6NmzJ3Q6XaPLlpiYWK+DW3h4OP79738DAJ5//nmsWrUKnTt3xvDhwzFixAhERERALBbjiSeegIeHh37f8OHD9c35xoyau+/Szaczruu44dwqUuhRLEKIabG0tDRYnzlzJrZs2YKlS5fiyJEjiI2NRVBQECoqKu57HTMzw1EXBQLBfRNqQ8ezNn5Kxs3NDUlJSfjmm28gk8kwefJkPProo6isrIRcLse5c+ewceNGqFQqzJs3DyEhIUY/bjvVpO/SyVqGv0T+8GaZyEk8DJeAJ/kOiRDSBmRmIiQsGsbbe7eWY8eOYcKECfpm5uLiYqSmprba+zVEqVTCyckJp0+f1t8H1mq1OHfuHLp3797o6/j7++PYsWOIjIzUbzt27BgCAgL06zKZDBEREYiIiEBUVBT8/PwQHx+PHj16QCwWY8iQIRgyZAjmz58Pa2tr/PPPPxgzZkyLlbWlUZK+i0AgwCWXZ7E9JQThiqcQ+eBTCCHtgEAgaLEmZ2Pi4+ODzZs3IyIiAgKBAHPnzm1SE3NLefvtt7Fs2TJ06dIFfn5++Oqrr5Cfn9+ke/Hvvfcexo4di9DQUAwZMgR//fUXNm/erO+tvm7dOmi1WvTp0wcWFhb45ZdfIJPJ4OHhge3btyM5ORmPPvoobGxssHPnTuh0Ovj6+rZWkVtE+/uJbAG2Xfviu+s2EGSBkjQhxKStXLkSr776Kvr16wd7e3vMmjULarW6zeOYNWsWsrKy8Morr0AkEmHSpEkYNmxYkyahGDVqFP79739jxYoVmDZtGry8vBAdHY1BgwYB4KaJ/OSTTzBjxgxotVoEBQXhr7/+gp2dHaytrbF582YsWLAA5eXl8PHxwcaNGxEYGNhKJW4ZAtbWNw1a0M2bN+Hm5ob09HS4urq22HVjUvIw9rsTcJBLEPPhYBrbl5B2qLy8HCkpKfDy8oJUKuU7nA5Hp9PB398fY8eOxeLFi/kOp8Xc7+eqOTmLatINCHZVIliUisfLziDvdB7swsbyHRIhhJi0Gzdu4O+//8bAgQOh0Wjw9ddfIyUlBS+//DLfoRk16t3dAKmZCGOUVzFdvBkV53/lOxxCCDF5QqEQ69atQ+/evREeHo74+Hjs27cP/v7+fIdm1KgmfQ/lbv2xJeEKmKQfjLffHyGEmAY3NzccO3aM7zBMDiXpe1D598W0OBlCSqwpSRNCCOEFNXffQ6gbN9JYQkYhynkaKpAQQkjHRkn6HtxsZXCwFMNLl4Yb5/7mOxxCCCEdECXpexAIBIi0T8LfkllwPPQB3+EQQgjpgChJ34eFd18AgE1pClB67ynaCCGEkNZASfo+ArrUTraB9Bh+gyGEENLh8JqktVot5s6dCy8vL8hkMnh7e2Px4sVtPnPKvQS7KnGOdQUAFF09ynM0hBDSMgYNGoTp06fr1z09PbFq1ar7niMQCLB169aHfu+Wus79LFiwoEkTdxgzXh/BWr58OdasWYOff/4ZgYGBOHPmDCZOnAilUompU6fyGRoAwMJcjFuKEKDkECpSTvAdDiGkg4uIiEBlZSV2795db9+RI0fw6KOPIi4uzmAu6MY4ffp0vSkuH9aCBQuwdetWxMbGGmzPzMyEjY1Ni75Xe8ZrTfr48eN45plnMHLkSHh6euK5557D0KFDERNjPE3LArdHAACKvAtA1f3nXyWEkNb02muvYe/evbh582a9fdHR0ejVq1eTEzQAODg4wMLCoiVCfCBnZ2dIJJI2ea/2gNck3a9fP+zfvx9XrlwBAMTFxeHo0aN48knjmcPZzScYuUwOM1YBZMbxHQ4hpAN76qmn4ODggHXr1hlsLy4uxu+//47XXnsNubm5eOmll9CpUydYWFggKCgIGzduvO91727uvnr1Kh599FFIpVIEBARg79699c6ZNWsWunbtCgsLC3Tu3Blz585FZWUlAG7KyIULFyIuLg4CgQACgUAf893N3fHx8Xj88cchk8lgZ2eHSZMmobi4WL9/woQJGDVqFFasWAGVSgU7OztERUXp36sxdDodFi1aBFdXV0gkEnTv3t2gNaKiogJTpkyBSqWCVCqFh4cHli1bBgBgjGHBggVwd3eHRCKBi4tLm7b08trcPXv2bKjVavj5+UEkEkGr1WLJkiUYN25cg8drNBpoNBr9elFRUavH2MPDFud0XfGE6CyqUo9B7Na71d+TEMKjipKmnyOSAKLqP6faKkCrAQRCwEz24OuaN76ZWSwW45VXXsG6deswZ84c/Qx9v//+O7RaLV566SUUFxejZ8+emDVrFhQKBXbs2IHx48fD29sbYWFhD3wPnU6HMWPGwMnJCadOnUJhYaHB/esacrkc69atg4uLC+Lj4/HGG29ALpfj/fffxwsvvICLFy9i9+7d+rmelUplvWuUlJRg2LBh6Nu3L06fPo3s7Gy8/vrrmDJlisEXkQMHDkClUuHAgQO4du0aXnjhBXTv3h1vvPFGoz63f//73/j888/x3XffITQ0FD/99BOefvppXLp0CT4+Pvjyyy+xbds2/Pbbb3B3d0d6ejrS09MBAH/++Se++OILbNq0CYGBgcjKykJcXNtV2HhN0r/99hvWr1+PDRs2IDAwELGxsZg+fTpcXFwQGVl/Judly5Zh4cKFbRqjh50F/if2xxPsLIqvHoP1gOlt+v6EkDa21KXp5zy/Dggczb2+/Bfw+wTAoz8wcUftMauCgNLc+ucuKGzSW7366qv47LPPcOjQIf08ytHR0Xj22WehVCqhVCoxc+ZM/fFvv/029uzZg99++61RSXrfvn24fPky9uzZAxcX7rNYunRpvRbOjz76SP/a09MTM2fOxKZNm/D+++9DJpPBysoKYrEYzs7O93yvDRs2oLy8HP/5z3/098S//vprREREYPny5XBycgIA2NjY4Ouvv4ZIJIKfnx9GjhyJ/fv3NzpJr1ixArNmzcKLL74IgOsPdeDAAaxatQqrV69GWloafHx80L9/fwgEAnh4eOjPTUtLg7OzM4YMGQIzMzO4u7s36nNsKbw2d7/33nuYPXs2XnzxRQQFBWH8+PF455139M0Md/vggw9QWFioXxISElo9RoFAgFKnXgAASeZpwEh6nhNCOiY/Pz/069cPP/30EwDg2rVrOHLkCF577TUA3FMzixcvRlBQEGxtbWFlZYU9e/YgLS2tUddPTEyEm5ubPkEDQN++fesd9+uvvyI8PBzOzs6wsrLCRx991Oj3qPteISEhBp3WwsPDodPpkJSUpN8WGBgIkUikX1epVMjOzm7Ue6jVamRkZCA8PNxge3h4OBITEwFwTeqxsbHw9fXF1KlT8ffftaNMPv/88ygrK0Pnzp3xxhtvYMuWLaiqqmpSOR8GrzXp0tJSCIWG3xNEIhF0Ol2Dx0skEoMOB2q1ulXjq2HjEwZNphiyynwgLxmw826T9yWE8ODDjKafI6rTEcovgruG4K460PT4h4urjtdeew1vv/02Vq9ejejoaHh7e2PgwIEAgM8++wz//ve/sWrVKgQFBcHS0hLTp09HRUXLdXw9ceIExo0bh4ULF2LYsGFQKpXYtGkTPv/88xZ7j7rMzMwM1gUCwT3zRHP06NEDKSkp2LVrF/bt24exY8diyJAh+OOPP+Dm5oakpCTs27cPe/fuxeTJk/UtGXfH1Rp4rUlHRERgyZIl2LFjB1JTU7FlyxasXLkSo0eP5jOseoI9nHCBdeZW0k7yGwwhpHWZWzZ9EdWp74jE3La696Pvd91mGDt2LIRCITZs2ID//Oc/ePXVV/X3p48dO4ZnnnkG//rXvxASEoLOnTvrO+c2hr+/P9LT05GZmanfdvKk4d+948ePw8PDA3PmzEGvXr3g4+ODGzduGBbX3Bxa7f0nJ/L390dcXBxKSmrv1x87dgxCoRC+vr6Njvl+FAoFXFxc6k2TeezYMQQEBBgc98ILL+D777/Hr7/+ij///BN5edxIkzKZDBEREfjyyy9x8OBBnDhxAvHxLfel6354rUl/9dVXmDt3LiZPnozs7Gy4uLjg//7v/zBv3jw+w6onxM0a/9H5wQplcNEw1O/+QAghbcfKygovvPACPvjgA6jVakyYMEG/z8fHB3/88QeOHz8OGxsbrFy5Erdv3zZISPczZMgQdO3aFZGRkfjss8+gVqsxZ84cg2N8fHyQlpaGTZs2oXfv3tixYwe2bNlicIynpydSUlIQGxsLV1dXyOXyeo9ejRs3DvPnz0dkZCQWLFiAO3fu4O2338b48eP196NbwnvvvYf58+fD29sb3bt3R3R0NGJjY7F+/XoAwMqVK6FSqRAaGgqhUIjff/8dzs7OsLa2xrp166DVatGnTx9YWFjgl19+gUwmM7hv3Zp4rUnL5XKsWrUKN27cQFlZGa5fv46PP/4Y5ubmfIZVj6VEjG32b+DJiuU4bjmY73AIIQSvvfYa8vPzMWzYMIP7xx999BF69OiBYcOGYdCgQXB2dsaoUaMafV2hUIgtW7agrKwMYWFheP3117FkyRKDY55++mm88847mDJlCrp3747jx49j7ty5Bsc8++yzGD58OB577DE4ODg0+BiYhYUF9uzZg7y8PPTu3RvPPfccBg8ejK+//rppH8YDTJ06FTNmzMC7776LoKAg7N69G9u2bYOPjw8ALhd9+umn6NWrF3r37o3U1FTs3LkTQqEQ1tbW+P777xEeHo7g4GDs27cPf/31F+zs7Fo0xnsRMGMZg7MZbt68CTc3N6Snp8PV1bVV3+vDLfHYcCoNkx7tjA9H+LfqexFCWl95eTlSUlLg5eUFqVTKdziknbjfz1VzchZNsNFIPdy5YewupGYD5U17ZIIQQghpDkrSjRTqbo23RNuw7vaz0B5unR6MhBBCSF2UpBups70lSs1tIBVUoiS9bXr1EUII6dgoSTeSQCBATqcn8Jjmc/zpSzVpQgghrY+SdBP4erkjhalwPp3uSRNCCGl9lKSboKbz2Lm0fJ4jIYS0FBN+wIUYoZb+eaIk3QQhbkoECZMxu/gTlG1+m+9wCCEPoWZIx9LSUp4jIe1Jzc9TSw0ZyuuIY6ZGLjVDFxtzPFVyCpqkqwD7Eqgeio8QYlpEIhGsra31EzVYWFjoh9YkpKkYYygtLUV2djasra0NJgR5GJSkm8jSqyc08WaQaPJosg1CTFzNNIqNnVGJkAextra+7/ScTUVJuomCPZxw4YIXeguuAGknKEkTYsIEAgFUKhUcHR1RWVnJdzjExJmZmbVYDboGJekm6uFhjX06X/QWXoHuxkkIQ//Fd0iEkIckEola/I8rIS2BOo41UWd7K1wSc2N3V6Se4DkaQggh7Rkl6SYSCgXQduoDAJAWXANK83iOiBBCSHtFSboZunq545quemq49FP8BkMIIaTdoiTdDKHuNjij68qtpJ3kNxhCCCHtFiXpZujuZo2zjEvSlXRfmhBCSCuhJN0MSpkZ7lj3AAAIM88DVRqeIyKEENIeUZJuJkdPf+QwBUS6CiAzju9wCCGEtEOUpJuph4ctzurvS1OTNyGEkJZHSbqZQt1tsE47DO/opqOq2wt8h0MIIaQdoiTdTD6OVrhoFoItFWFIKpHxHQ4hhJB2iJJ0MwmFAnR3twYAnE8r4DUWQggh7RMl6YcQ6maNQEEqbM9+CVz/h+9wCCGEtDM0wcZDCPWwgVR0EiPubAMuagDvx/kOiRBCSDtCNemHEOpmjSO6IGzXPoJil3C+wyGEENLOUJJ+CNYW5rhtF4YplVMRI6daNCGEkJZFSfoh9XC3AUCdxwghhLQ83pP0rVu38K9//Qt2dnaQyWQICgrCmTNn+A6r0ULdrQEwZF6/ANw6y3c4hBBC2hFeO47l5+cjPDwcjz32GHbt2gUHBwdcvXoVNjY2fIbVJD3cbTBKeAwrbn8DtqsPBK//zXdIhBBC2glek/Ty5cvh5uaG6Oho/TYvLy8eI2q6rk5yJIm54UFZxnkIKssBMynPURFCCGkPeG3u3rZtG3r16oXnn38ejo6OCA0Nxffff3/P4zUaDdRqtX4pKipqw2gbJhIKYOPqhxymgFBXAWTG8h0SIYSQdoLXJJ2cnIw1a9bAx8cHe/bswVtvvYWpU6fi559/bvD4ZcuWQalU6peAgIA2jrhhPTxscUbny62kneQ3GEIIIe0Gr0lap9OhR48eWLp0KUJDQzFp0iS88cYb+Pbbbxs8/oMPPkBhYaF+SUhIaOOIGxbqbo0zNTNipZ/iNxhCCCHtBq9JWqVS1asN+/v7Iy0trcHjJRIJFAqFfpHL5W0R5gOFutvop63UpZ0CGOM5IkIIIe0Br0k6PDwcSUlJBtuuXLkCDw8PniJqHltLcxTZBKCcmUFYlgvkXuM7JEIIIe1As5J0eno6bt68qV+PiYnB9OnTsXbt2iZd55133sHJkyexdOlSXLt2DRs2bMDatWsRFRXVnLB4FezhiDjmza2kneA3GEIIIe1Cs5L0yy+/jAMHDgAAsrKy8MQTTyAmJgZz5szBokWLGn2d3r17Y8uWLdi4cSO6deuGxYsXY9WqVRg3blxzwuJVqEdtkzfS6L40IYSQh9esJH3x4kWEhYUBAH777Td069YNx48fx/r167Fu3bomXeupp55CfHw8ysvLkZiYiDfeeKM5IfEu1K228xhLpx7ehBBCHl6zknRlZSUkEgkAYN++fXj66acBAH5+fsjMzGy56EyIn7MciWJ/AIAg9xpQksNzRIQQQkxds5J0YGAgvv32Wxw5cgR79+7F8OHDAQAZGRmws7Nr0QBNhVgkhIdrJ1zVdeI20KNYhBBCHlKzkvTy5cvx3XffYdCgQXjppZcQEhICgBtBrKYZvCMKdbfBaZ0vss3dAW0F3+EQQggxcc0au3vQoEHIycmBWq02mAxj0qRJsLCwaLHgTE0Pdxv8X9WrWCdT4O/AgXyHQwghxMQ1qyZdVlYGjUajT9A3btzAqlWrkJSUBEdHxxYN0JSEultDByGuZhdDXV7JdziEEEJMXLOS9DPPPIP//Oc/AICCggL06dMHn3/+OUaNGoU1a9a0aICmxN5KAndbCzAGxKXeASpK+A6JEEKICWtWkj537hwGDBgAAPjjjz/g5OSEGzdu4D//+Q++/PLLFg3Q1PRwt8Y74j/wyG+hQEzTBnchhBBC6mpWki4tLdWPm/33339jzJgxEAqFeOSRR3Djxo0WDdDUhLrboIjJYKYrBzLj+A6HEEKICWtWku7SpQu2bt2K9PR07NmzB0OHDgUAZGdnQ6FQtGiApqaHuw3+pw3Hs/gcujE/8h0OIYSQpqgsA/JvAJXlfEcCoJm9u+fNm4eXX34Z77zzDh5//HH07dsXAFerDg0NbdEATY2fSo4iM1ucLdchObcMXRyt+A6JEEI6LsaA8gJugKnibKDkDrfUvJYqgCfqDGf9dRhQmAa8thdw4/+R4mYl6eeeew79+/dHZmam/hlpABg8eDBGjx7dYsGZIjOREMGdrBGTmodzafmUpAkhpK1c3gEkbq9OxNlcYi65c/9xK6zdDZO0lQNQfBvQqFs/3kZoVpIGAGdnZzg7O+tnw3J1de3QA5nUFephjcobp9D1aDRQ0A0YsoDvkAghpH3Z8S5w4wQw5jvAOYjbVpAOxG1o+HiJArB04BYrB8DSkXut7GR43IQdgFgKCAStG38jNStJ63Q6fPzxx/j8889RXFwMAJDL5Xj33XcxZ84cCIW8TlPNu1A3G1wRFKN7wV4gIZmSNCGENEVpHpCdANxOALIvAdmJQGUp8ObR2mOyE7l9WRdrk7T348DgebUJWJ+M7QEzWePeu7HHtZFmJek5c+bgxx9/xCeffILw8HAAwNGjR7FgwQKUl5djyZIlLRqkqenhbo1ZOh9uJe86sPElwK0P4N4XcOkOiCW8xkcIIUahshy4c7k24d5O4JJz0T0matIUARLuySIMeBfoNxVw7V2736Er4PBu68fdhpqVpH/++Wf88MMP+tmvACA4OBidOnXC5MmTO3ySdlRIYWXtgMMlQXhUFA8k7eQWABBJgE49APdHuKTtFgbIbO5/QUIIMWaVZUBZPlBWwHXScnsEqGlRvbgZSDsB+D7J1XQB4NY5YMNYoDQXYLqGr2ntDjgGAo7+gFMg4BgAmNUZdrrL4NYskdFoVpLOy8uDn59fve1+fn7Iy8t76KDagx4eNpgY9z6W9dBirNNNIO0kt5TmcD+waScAfMEd7OAP9JsChP6L15gJIcRARQlw+xJX272TxHXEKi8wTMhlBYBWY3je7DRAquReJx8Ezv3MNT/XJGmxlOvQBXCVFMdAwCmAS8ROgYCDH9frmjQvSYeEhODrr7+uN7rY119/jeDg4BYJzNT1cLfGX3EZ2F2owtjRo4F+b3OPAuRer07SJ4H0k0DuNeBOIlBV55m8nKvAgSVA50FAzwl8FYEQ0pFkXQRuxgCq7lxrH8BNufvfRj6xIxABMmtAas3VrGuStM9QLkG796091rYz8Oax6vvGjkbTScsYNStJf/rppxg5ciT27dunf0b6xIkTSE9Px86dO1s0QFMV6s41YZ9PywdjDAKBgPtBtO/CLT3GcwcW3+GStUud58tTjwCXtnDfWusm6VPfAfZduUXuDAhFbVcgQojpK8mprhVX14yHLATMq5uQT/8AnI3m7vXWJGkHP0DuAjj6Afa+gELFJWGZNVcDrnkttebuFTeUbP2f4pa6zKSAc7dWK2Z70qwkPXDgQFy5cgWrV6/G5cuXAQBjxozBpEmT8PHHH+vH9e7IAlQKSMRC5JdWYuBnBzEyWIWnglUIUCm4hF3DygHwjzA82b0f8PhHgNK9dltJLrDr/dp1gQiQqwClK/cIgaJT9WvX2tcWdvQNlZCOgDGu93NFKfdvZSnXnHwnieuUdSeJS8ylOYbndR/HdWYFuM6thTcBW+/a/QoX4N3ENisGqU/AGGMtdbG4uDj06NEDWq22pS55Xzdv3oSbmxvS09Ph6uraJu/ZFF/tv4pvDl5HWWXt59HZ3hJPBavwVIgLujrJG3+xgjRg/yIgPYb7RWKN+IzFUuDV3bW19JtngKx4br3mF5MQwp/KciA/hbsNVl7ANRNXlNQm2pqkO+gDwMaDO+fcf4HjX3EdsZ5YyG0rLwQ+cb/n2xiw9uBqyI5+XEudbefWKBlpQHNyVrMHMyEP9vZgH7w2wAv7E7Ox40Im/knKRnJOCb785xq+/OcaujpZYWSQC54KUcHb4QEjk1m7A8/+wL3WabkRcQpvcov6FlB4C1BXrxfe4kbbqSoHLOxrr5H4F3BsFdDnzdokXZoHrHuK+wNg7QHYeNZ57QGYW7bCJ0NIB1WSAxxazvVFyb3GDb6BRtSTek6sTdKaIiAnqfbZYMCw17NYxjVhS60BB9/qxY9b7H3od9rEUJJuZRbmYkSEuCAixAXFmirsS7iN7RcycOjKHVy5XYwrt6/gi31X4K9S4KlgFSKCXeBuZ3H/iwpFXDOUwuXeY8tWaQB1BndMDXsfwGcY1zGkRkFa9WABlxq+jqVDA8nbk3tfI3vonxBeleQCEqvacRDifuW+FHs/DgyrfixVZF5/CluJErDz5m5PmVsAZpbc75a5BZd8zSwMR8Xyj+AStFxVu01kBnxwizu2gw8m1d5Qkm5DVhIxRoV2wqjQTigsq8Tfl7Kw/UImjl3LQWKmGomZany2JwnBrko8FazCyGAXdLJuZiIUSwBbL8Ntof+q/5iXbWdg3J9AQSo380t+KlBQ/W95Ye1g9LfOGJ43PZ6r3QPA+V+4XqABzwBdhnDbtFWArpISOWkfKstrHzcqL+AG28i9xjVT19SKy/KByO2AV3WfHF0lNzCHlVPtdaQKrula4QLY+QB2XbjRsJrSd8TajVvuJqF5AtqjJiXpMWPG3Hd/QUHBw8TSoShlZni+lxue7+WG/JIK7KlO2Mev5+DCzUJcuFmIpTsvo4e7NZ4KdsHIYBWcFNKWD0SqAHyGNLyvrKA2YeffqH1deJPrnFbj+j/AxT+5Pzo1STozDvjhca5WYGnPLRY1/9pVj6Fbs6163cK+tqcpIS2tSlP7fK/CpfY53Kx4bmIGpRsQOo7bxhiwJpwbbKO8wPARyfspvFn72vtx7guwQ1fDYwbNftiSkA6kSUlaqVQ+cP8rr7zyUAF1RDaW5ngxzB0vhrkjp1iDXRezsD0uo3omrQKcSyvA4h0J6O1pi4hgFfp626OzvSWEwlbuuS2z5hZVyP2PC3mJeyzMs3/ttppepJUlQEEJl+AbY+Y1rsc7AJyJ5jrKdXu29otERSlXa7Fy5JK6iBqDOjzGuL4V+j4Zdy3qDC7ZVpXVnvPiRsBvBPf6dgJwcBk3LkFNkhYIuL4e5QW15wiEtY8cWdhztWA7b+5fex/AxsvwS2bNLSlCHkKT/sJFR0e3Vhykmr2VBOMf8cD4RzxwW12OnfGZ2H4hE2dv5CMmJQ8xKdyIblYSMQJdFAjqpESQqxLBrtbwsLVo/cTdEJ8nuMVg21Bu1KGSHO4PZM2UcaU53L07/evqpTQH0FYCFra110g9wtXQnYNqk/TtS8CPNTV/AXe8pWPtQPpWjrUDJNTdLlfRvTpTl58KpBzhkmTNY4vaKq5Xc2VJIy8i4AbZ0FXWbnLw5TpmOQYYHvryb9zzvDWJ2VxOP0OkzVE1xIg5KaSYGO6FieFeuFVQhl3xmdhzKQvxtwpRrKnCqZQ8nEqpHYZVLhGjW3XSDuqkRLCrEu62FobPZbcVQfUfQ2l1p5gHYQyoKDYcoCXkJW6IQI86IxVVlXFJuCQHAOO+AJTmcqO23c9717nmdYAbFCbtBBDyMtB1KLet+A6QtAMwt+IGZTC34u7x1V03k9Fz542hreR6IAOGX7rSY7jHiao0XPNxvX+rX5cVVD+xkA48sRjwfqz6/NPAtimA54DaJC0Sc/9PlSXcvd+64wXoxw1w5W6pSK256QrvTrQu3QGXVfXL4d6nZT8XQprBaJL0J598gg8++ADTpk3DqlWr+A7H6HSyluH1AZ3x+oDOqNLqcP1OCS7cLMDFW4W4cKsQCRlqFGmqcCI5FyeSc/XnKaTi6qRtrU/crjYyfhL3/QgEtbPb1Giohu71KPDeNe4xtNJcoDibe9ysuHqS9+JsrpZed3t5ASCrkyxuHAcStnKDN9TIvQb8Ne0BMQq52pQ+eVsBL/1a2zwf/wfXgc5naG3cJTncSE5CESAU37XUbDO7a13MdT6q+Txyr3PP0irduFofwCWz5EPVgVU/wqMf8uAe6wDg0a92QpfMC8CNY9zgFTVfVqoqgL/ncNfXVtT5t/we2yq4cZtHf1vbHyH+d2DrW9z6v/6sfe//jGpCjbda3vXaJG1f3eeh7uh8ADDpINfPgWaXI+2QUSTp06dP47vvvqNxvxtJLBLC11kOX2c5nu/F9fKs0upwNbsY8TcLEV+duBMz1VCXV+HYtVwcu1abuK0tzLhm8uol2M0aLkqp8SXu+xGKuCZtK8cHH6vTGdaeek3kZiHzCK/dJrECfEdwNcCKYkBTXPu6gpszHUwHaAq5pW4cNVKPcsMqWtjXJuni29z9zqaKiqlNyHEbgcOfAWGTgBGfcdvKCoANzzf9uhN317ZM3DgG7J7N3fOvSdICYf1HhBqjok7yrUmW2grDYxx8ucQulnAD7ej/lRquS6yqa8RugKrO3wSX7oZJvwbd9yXtGO9Juri4GOPGjcP333+Pjz/+mO9wTJZYJIS/SgF/lQJje3OJu1Krw5XbRfrEHX+rEJczi1BQWokjV3Nw5GrtEIHOCil6etjolwAXBcxE7eT+293Nm50HcUtdzkHASxsbPl+n42qAmuqEXTeRS+t0puw6jGuKr9s8L7UGer0G6Kq42r+u+tE0g/Wq+ut1B6ewcgKcgw2Tkcis9nl3/ZcrwYPX69Y27X24BF23RUEkBh59j5tSVWx+17/Vy937xDKuWbmG/zPA3Nz6nfomHWj48yWE3FOLDgvaHJGRkbC1tcUXX3yBQYMGoXv37o1u7jb2YUGNUUUVl7gv3CxE/K0CXLhZiKSsIlTpDH8MpGZChLhao5cnl7R7uNvA2sKcp6gJIcT0mdywoJs2bcK5c+dw+vTpRh2v0Wig0dTOW1pUVNRaobVb5mIhunVSolsnJQBuMJKyCi3ibhbg7I18/VJYVlmvY1oXRyv0dLdBz+rE3dne0rSayAkhxMTwlqTT09Mxbdo07N27F1Jp4wbpWLZsGRYuXNjKkXU8MnMRHulsh0c62wEAdDqG5JxinL2RjzOp+Tiblo/kOyW4ll2Ma9nF+PVMOgDAxsKMq2V72KCXhy2CXZWQmtH0mYQQ0lJ4a+7eunUrRo8eDZGo9o+6VquFQCCAUCiERqMx2AfUr0nfunULAQEB1NzdBvJKKnDuBpewz6bmI+5mATRVOoNjzEQCBLoo0dPDBt3drPl9BIwQQoyMSTV3Dx48GPHx8QbbJk6cCD8/P8yaNateggYAiUQCiaS244tarW71OAnH1tIcQwKcMCSAG4e4okqHSxmF+ubxMzfycadIg9j0AsSmF+jPU0jFCHa15gZcqX6Gu5O1ET4CRgghRoi3JC2Xy9GtWzeDbZaWlrCzs6u3nRgfc7EQoe42CHW3wesDAMYYbuaX6ZP2hVuFSMzgHgE7ei0HR6/V9iS3szSvk7S5GnerjEtOCCEmjvdHsEj7IBAI4GZrATdbC4wK5SbfqOlJHn+rsHrSkAIkZRUht6QCB5Pu4GDSHf35jnIJgqsHXQl25Wrc9lY0OAUhpGPj/RGsh0GPYJme8kotLmcVIf5mQfVjYIW4crsIugZ+CjtZy/Rjk3d3s0aouzUszOl7JSHENJnUPWnSMUnNROjuZo3ubtb6baUVVUjIUOuT9oWbBUjOKcGtgjLcKijD7ktZAACxUIAgVyXCvGzxiJcdenraQCE146kkhBDS+ihJE95ZmIvRy9MWvTxrx9cuKq/EpQw14m8WIu5mAc7dyEdGYTnOpxXgfFoBvjuUDKEACHBRIMzTDmFetgjzsoWtJQ24QghpPyhJE6Mkl5oZPLtd0zHtVEoeYlJyEZOSh9TcUly8pcbFW2r8dCwFANDVyQp9vLik3cfLFo7UIY0QYsIoSROTULdj2nM9uXs5WYXliEnNw6lkLmlfzS7Gldvc8t+TNwAAXvaW6FNdyw7zsoWrjcX93oYQQowKJWlispyVUjwd4oKnQ7iJJ3KLNTidmoeTyXmISclDYpYaKTklSMkpwabT3Chpnaxl6ONliz6dbRHiZg1vB6v2M5EIIaTdoSRN2g07KwmGd1NheDcVAKCwrBJnUrmEfTIlDxdvFeJWQRk2n7+FzedvAeCe9/Z1kiNApUBgJwUCqmcSs5TQrwYhhH/0l4i0W0qZGQb7O2GwPzdKWommCmdv5CMmJQ8xqXlIyFCjWFOln8YTZ7jzBALA084SAS5c0g5wUSDQRQFHOd3fJoS0LUrSpMOwlIjxaFcHPNrVAQA3kUh6fikSMtS4lKFGQqYalzIKcVut0TeT77iQqT/f3kqCQJfapB2gUsDTzhJCIQ1xSghpHZSkSYclFArgYWcJDztLPBmk0m/PKdYgQZ+01UjIKERyTglyijU4dOUODl2pHSnNwlwEfxWXtLu5KNHbyxaedjSpCCGkZVCSJuQu9lYSgxo3wA24cjmryKDWfTlTjdIKrX688hoOcgnXm9yT61Hu6ySn2jYhpFkoSRPSCBbmYvRwt0EPdxv9tiqtDik5JbiUwTWTx6YXIC69EHeKNNhxIVPfVK6QitHbs/YxsG6dlNSjnBDSKJSkCWkmsUgIHyc5fJzk+klFyiu1iEsv0HdOO3sjH+ryKuy/nI39l7MBADIzEXp4WOtHSgt1t4bUrP7UrIQQQkmakBYkNROhT2c79KkeKa1Kq8OlDLU+aZ9OzUNBaSWOXcvFsWu5AAAzkQDBrtb6mnZPDxqTnBDCoVmwCGlDOh3D1exixFQ/vx2Tkovbao3BMUIB4K9SoLenLYJdlfBzVsDb0RISMdW2CTFlNAsWIUZOKBTA11kOX2c5xj/iAcYY0vPKcKp6PPLTqdyY5JeqO6jVEAsF6OxgCT9nBXyd5fBXyeHrrICLUko9yQlpxyhJE8IjgUAAdzsLuNtZ4PlebgCA2+pyxKRw97NrepGry6v045IjrvZ8uVQMP2e5QfLu6iSHnJrLCWkXKEkTYmScFFJEhLggonpMcsYYMgvLkZRVhMQsNZKyinA5swjX7xSjqLwKp1PzcTo13+Aarjayesnb084SYupVTohJoSRNiJETCARwsZbBxVqGx/wc9dsrqnS4fqe4XvLOUpfjZn4ZbuaXYV9itv54c7EQ/s5y9OtijwFd7NHT04bucxNi5ChJE2KizMVC+FdPCDIKnfTbC0orcDmriEvaWWr969IKLeJuFiLuZiHWHLwOqZkQfbzsMMDHHgN8HNDVyYrubxNiZChJE9LOWFuY45HOdnik+jEwoHac8rM38nH0ag6OXMvBnaK6w5wmwlEuQX8fewzwsUd4F3uaUIQQI0BJmpAOoO445WN6uIIxhqTbRThyhUvYMSm5yC7SYPO5W9h8jpvG089ZjgE+9ujv44AwT1vIzKlpnJC2Rs9JE0JQXsmNQX7kag6OXL1j8PgXwDWt9/a0wQAfB/TvYo8AlYLGIyekiZqTsyhJE0LqyS3W4Nj1XBy5cgdHr+Ugs7DcYL+dpTnCu9ijv489enrYwNPOEiJK2oTcFw1mQghpEXZWEjwd4oKnQ1zAGMP1O8U4cjUHR6/m4ERyLnJLKrAtLgPb4jIAcOOR+6nk1fNsKxHgooCvk5yayAl5SJSkCSH3JRAI0MVRji6OckwM90JFlQ7n07im8ePXc5CQqUZZpRbn0wpwPq1Af55QAHg7WCHARYEAlQKBLlzytrU0568whJgYStKEkCYxFwvrTCLiC62OISWnWD/PdkIGt+SWVOBqdjGuZhfjf7EZ+vOdFVKuxl0nebvZyujxL0IaQEmaEPJQRMLamvYz3bnntRljyC7ScAk7k5tvOyFDjdTcUmSpy5GlLtdP3QkAcokY/ioucXfrpESYpy0lbkJASZoQ0goEAgGcFFI4KaQGo6QVa6pwOZObPKQmgSdlFaFIU8XNDJaapz9WpZTqp+/s42UHbwdLStqkw+E1SS9btgybN2/G5cuXIZPJ0K9fPyxfvhy+vr58hkUIaSVWEjF6edqil6etflulVofkOyW4lFGISxlqxKUXIO5mATILy/G/2Ax9U7m9lTmXtD1tEeZlBz9nOT0GRto9Xh/BGj58OF588UX07t0bVVVV+PDDD3Hx4kUkJCTA0tLygefTI1iEtE9lFVqcT8/HqWRu3u1zafnQVOkMjlFIxfpadpiXLQJdFDSBCDFqJv+c9J07d+Do6IhDhw7h0UcffeDxlKQJ6Rg0VVrE3yzEqZQ8nErJw9nUPJRUaA2OsTQXoaenLfp4cUuQq5ImECFGxeSfky4sLAQA2NraNrhfo9FAo9Ho14uKitokLkIIvyRikb6ZPOoxoEqrw6UMNWJS8nAqJRcxKXlQl1fh8JU7OHzlTvU5QvRwt0GYly26dVLC28ES7rYWVNsmJsVoatI6nQ5PP/00CgoKcPTo0QaPWbBgARYuXFhvO9WkCenYdDqGy1lFiEnJRUxqHk4l5yG3pKLecWYibgzzLg5W8Ha0hLeDFbwdrNDZwRJyqRkPkZOOxKSbu9966y3s2rULR48evWfwd9ekb926hYCAAErShBAD3ChpJTiVkoszqfm4ml2E69klKKvU3vMcZ4XUIHF7O1ihi6MVnBQS6lVOWoTJNndPmTIF27dvx+HDh+8buEQigUQi0a+r1ep7HksI6bi4UdK4JDuujwcArradqS7H9exiXL9TjGvV/16/U4I7RRr989vHruUaXMvSXARvx9qk7e1gCV9nBTztLCh5k1bHa5JmjOHtt9/Gli1bcPDgQXh5efEZDiGkHRMKBehkLUMnaxke7epgsK+wrBLJ+sRdUp28i3EjtxQlFVpcuFmICzcLDc7pZC3DIF8HDPJ1RD9vO1hKjKLOQ9oZXn+qoqKisGHDBvzvf/+DXC5HVlYWAECpVEImk/EZGiGkA1HKzBDqboNQdxuD7RVVOqTlleBadm3ivp5djMTMItwqKMP6U2lYfyoN5iIhenvZYFBXRwz0dYCPoxXVskmL4PWe9L1+iKOjozFhwoQHnk+PYBFC+FBaUYWTybk4mHQHB5PuIC2v1GB/TW19kK8DwrvYw4pq2QQmeE/aSPqsEUJIk1iYi/G4nxMe93MCYwwpOSVcwr5yByeTc3GroAwbY9KwMSYNZiIBennYYpCvAwb6OsDXSU61bNJoRtO7uzmoJk0IMTZlFVqcTM7FoSt3cDApG6m5hrVslVKKgXVq2fToV8dh0o9gNQclaUKIsUvNKcHBpGwcvHIHJ67nGgxvKhYK0NPDBoN8HeGvkqOTtQwqaxk1j7dTJtfcTQgh7Z2nvSUm2HthQrgXyiu1+nvZh67cQUpOiX6o07rkUjFclDKorKVQKWVwUUqhsq79V6WUQmpGQ552BJSkCSGkjUjNRBjk64hBvtz0nTdyS3Doyh0cuZqDtNxSZBSWoai8CkXlVUgqL0LS7XsPfWxraQ6VsjqJWxv+q1JK4ayUwoyGQDV5lKQJIYQnHnaWeKWvJV7p66nfVqypQmZBGTIKyw3+zSwsR0ZhGTILylFWqUVeSQXySipwKaPhQZ3MRUKEuCkR5mWL3p626OlhQ/e/TRAlaUIIMSJWEjF8nOTwcZI3uJ8xhsKySmQUlCOz8K4kXv1vVmE5KrQ6nE7Nx+nUfADXIRQAAS4KhHnaVSduG9hZSRp8D2I8KEkTQogJEQgEsLYwh7WFOQJcFA0eo9Mx3Mgrxenq+92nU/OQlleKi7fUuHhLjZ+OpQAAujhaoXf19J69vWzRyZoGkTI2lKQJIaSdEQoF8LK3hJe9Jcb2dgMAZBWWIyY1DzEpuTidko+k20W4ls0NhboxJg0ANwhLmJetvonc28GSnunmGT2CRQghHVB+SQXO3Mivnt4zHxdvFUKrM0wHdpbm6O1pq0/cHnYWsJKIKXE3Ez2CRQghpFFsLM3xRIATnghwAgCUaKpwPq1APyf3+bQC5JZUYPelLOy+lKU/TyQUQCkzg1JmBoXMDNbVr60tzPTblfpt5gb76LGxpqMkTQghBJYSMfr72KO/jz0AQFOlxcVbhdw97ZQ8nL2RD3V5FbQ6pu9Z3lQSsbBOAjeDvZUEfs4KBLhwi4tSSrX0u1CSJoQQUo9ELEJPD1v09LAFBnHbyiu1KCyrRGFZJQpKa/6tQGFZJdRllSi4a1/dRatj0FTpkF2kQXaRRv8+uy7W1tIVUjGXsFVK+KvkCHBRwMdRDnNxx33em5I0IYSQRpGaiSA1E8FJIW3SeYwxFGuq9Mm7JqFnFJQhIVONxMwiXL1dBHV5FU4m5+Fkcu0IbGYiAbo4yrmkraqudasUsLYwb+niGSVK0oQQQlqVQCCAXGoGudQMbvc4RlOlxbXsYiRkqKsTtxoJGWqoy6uQWL2+Gbf0x3eylhkkbn+VAm42FhAK21dzOSVpQgghvJOIRQh0USLQRanfxhjDrYIyJGRwte2EzEIkZKqRnleGWwXcsi8xW3+8lUQMR4WE+0IgEUMuFcNKIoZcagYrqRiKu9atJNXbpNw2CzOR0SV5StKEEEKMkkAggKuNBVxtLDA00Fm/vbCsEpdratvVy5WsYhRrqlB8p+oh3o9L9PI6iVwuFSPqsS7o7WnbEkVqMkrShBBCTIpSZoY+ne3Qp7OdflulVoeUnBLklVSgqLwKxZpK/WQlxZoqFJVXorh6vUhTpT+mZluVjoEx6M9BYbn+2uMf8eCjmAAoSRNCCGkHzERCdL3HeOcPwhjX81xdJ5HXJPai8qp7Dr/aFihJE0II6dAEAoG+57pj8/J8q+m4D58RQgghRo6SNCGEEGKkKEkTQgghRoqSNCGEEGKkKEkTQgghRsqke3frdDoAQGZmJs+REEIIIfdXk6tqcldjmHSSvn37NgAgLCyM50gIIYSQxrl9+zbc3d0bdayAMcZaOZ5WU1VVhfPnz8PJyQlC4cO33BcVFSEgIAAJCQmQy43sYTkjRp9b09Fn1jz0uTUPfW7N09Kfm06nw+3btxEaGgqxuHF1ZJNO0i1NrVZDqVSisLAQCgV/I8yYGvrcmo4+s+ahz6156HNrHmP43KjjGCGEEGKkKEkTQgghRoqSdB0SiQTz58+HRCLhOxSTQp9b09Fn1jz0uTUPfW7NYwyfG92TJoQQQowU1aQJIYQQI0VJmhBCCDFSlKQJIYQQI0VJutrq1avh6ekJqVSKPn36ICYmhu+QjNqyZcvQu3dvyOVyODo6YtSoUUhKSuI7LJPzySefQCAQYPr06XyHYvRu3bqFf/3rX7Czs4NMJkNQUBDOnDnDd1hGTavVYu7cufDy8oJMJoO3tzcWL14M6opk6PDhw4iIiICLiwsEAgG2bt1qsJ8xhnnz5kGlUkEmk2HIkCG4evVqm8RGSRrAr7/+ihkzZmD+/Pk4d+4cQkJCMGzYMGRnZ/MdmtE6dOgQoqKicPLkSezduxeVlZUYOnQoSkpK+A7NZJw+fRrfffcdgoOD+Q7F6OXn5yM8PBxmZmbYtWsXEhIS8Pnnn8PGxobv0Iza8uXLsWbNGnz99ddITEzE8uXL8emnn+Krr77iOzSjUlJSgpCQEKxevbrB/Z9++im+/PJLfPvttzh16hQsLS0xbNgwlJeXt35wjLCwsDAWFRWlX9dqtczFxYUtW7aMx6hMS3Z2NgPADh06xHcoJqGoqIj5+PiwvXv3soEDB7Jp06bxHZJRmzVrFuvfvz/fYZickSNHsldffdVg25gxY9i4ceN4isj4AWBbtmzRr+t0Oubs7Mw+++wz/baCggImkUjYxo0bWz2eDl+TrqiowNmzZzFkyBD9NqFQiCFDhuDEiRM8RmZaCgsLAQC2trY8R2IaoqKiMHLkSIOfO3Jv27ZtQ69evfD888/D0dERoaGh+P777/kOy+j169cP+/fvx5UrVwAAcXFxOHr0KJ588kmeIzMdKSkpyMrKMvhdVSqV6NOnT5vkCJOeBasl5OTkQKvVwsnJyWC7k5MTLl++zFNUpkWn02H69OkIDw9Ht27d+A7H6G3atAnnzp3D6dOn+Q7FZCQnJ2PNmjWYMWMGPvzwQ5w+fRpTp06Fubk5IiMj+Q7PaM2ePRtqtRp+fn4QiUTQarVYsmQJxo0bx3doJiMrKwsAGswRNftaU4dP0uThRUVF4eLFizh69CjfoRi99PR0TJs2DXv37oVUKuU7HJOh0+nQq1cvLF26FAAQGhqKixcv4ttvv6UkfR+//fYb1q9fjw0bNiAwMBCxsbGYPn06XFxc6HMzER2+udve3h4ikUg/N3WN27dvw9nZmaeoTMeUKVOwfft2HDhwAK6urnyHY/TOnj2L7Oxs9OjRA2KxGGKxGIcOHcKXX34JsVgMrVbLd4hGSaVSISAgwGCbv78/0tLSeIrINLz33nuYPXs2XnzxRQQFBWH8+PF45513sGzZMr5DMxk1eYCvHNHhk7S5uTl69uyJ/fv367fpdDrs378fffv25TEy48YYw5QpU7Blyxb8888/8PLy4jskkzB48GDEx8cjNjZWv/Tq1Qvjxo1DbGwsRCIR3yEapfDw8HqP+F25cgUeHh48RWQaSktLIRQa/pkXiUTQ6XQ8RWR6vLy84OzsbJAj1Go1Tp061SY5gpq7AcyYMQORkZHo1asXwsLCsGrVKpSUlGDixIl8h2a0oqKisGHDBvzvf/+DXC7X35tRKpWQyWQ8R2e85HJ5vfv2lpaWsLOzo/v59/HOO++gX79+WLp0KcaOHYuYmBisXbsWa9eu5Ts0oxYREYElS5bA3d0dgYGBOH/+PFauXIlXX32V79CMSnFxMa5du6ZfT0lJQWxsLGxtbeHu7o7p06fj448/ho+PD7y8vDB37ly4uLhg1KhRrR9cq/cfNxFfffUVc3d3Z+bm5iwsLIydPHmS75CMGoAGl+joaL5DMzn0CFbj/PXXX6xbt25MIpEwPz8/tnbtWr5DMnpqtZpNmzaNubu7M6lUyjp37szmzJnDNBoN36EZlQMHDjT49ywyMpIxxj2GNXfuXObk5MQkEgkbPHgwS0pKapPYaBYsQgghxEh1+HvShBBCiLGiJE0IIYQYKUrShBBCiJGiJE0IIYQYKUrShBBCiJGiJE0IIYQYKUrShBBCiJGiJE0IIYQYKUrShJBmEwgE2Lp1K99hENJuUZImxERNmDABAoGg3jJ8+HC+QyOEtBCaYIMQEzZ8+HBER0cbbJNIJDxFQwhpaVSTJsSESSQSODs7Gyw2NjYAuKboNWvW4Mknn4RMJkPnzp3xxx9/GJwfHx+Pxx9/HDKZDHZ2dpg0aRKKi4sNjvnpp58QGBgIiUQClUqFKVOmGOzPycnB6NGjYWFhAR8fH2zbtk2/Lz8/H+PGjYODgwNkMhl8fHzqfakghNwbJWlC2rG5c+fi2WefRVxcHMaNG4cXX3wRiYmJAICSkhIMGzYMNjY2OH36NH7//Xfs27fPIAmvWbMGUVFRmDRpEuLj47Ft2zZ06dLF4D0WLlyIsWPH4sKFCxgxYgTGjRuHvLw8/fsnJCRg165dSExMxJo1a2Bvb992HwAhpq5N5toihLS4yMhIJhKJmKWlpcGyZMkSxhg3neibb75pcE6fPn3YW2+9xRhjbO3atczGxoYVFxfr9+/YsYMJhUKWlZXFGGPMxcWFzZkz554xAGAfffSRfr24uJgBYLt27WKMMRYREcEmTpzYMgUmpAOie9KEmLDHHnsMa9asMdhma2urf923b1+DfX379kVsbCwAIDExESEhIbC0tNTvDw8Ph06nQ1JSEgQCATIyMjB48OD7xhAcHKx/bWlpCYVCgezsbADAW2+9hWeffRbnzp3D0KFDMWrUKPTr169ZZSWkI6IkTYgJs7S0rNf83FJkMlmjjjMzMzNYFwgE0Ol0AIAnn3wSN27cwM6dO7F3714MHjwYUVFRWLFiRYvHS0h7RPekCWnHTp48WW/d398fAODv74+4uDiUlJTo9x87dgxCoRC+vr6Qy+Xw9PTE/v37HyoGBwcHREZG4pdffsGqVauwdu3ah7oeIR0J1aQJMWEajQZZWVkG28Risb5z1u+//45evXqhf//+WL9+PWJiYvDjjz8CAMaNG4f58+cjMjISCxYswJ07d/D2229j/PjxcHJyAgAsWLAAb775JhwdHfHkk0+iqKgIx44dw9tvv92o+ObNm4eePXsiMDAQGo0G27dv139JIIQ8GCVpQkzY7t27oVKpDLb5+vri8uXLALie15s2bcLkyZOhUqmwceNGBAQEAAAsLCywZ88eTJs2Db1794aFhQWeffZZrFy5Un+tyMhIlJeX44svvsDMmTNhb2+P5557rtHxmZub44MPPkBqaipkMhkGDBiATZs2tUDJCekYBIwxxncQhJCWJxAIsGXLFowaNYrvUAghzUT3pAkhhBAjRUmaEEIIMVJ0T5qQdoruZBFi+qgmTQghhBgpStKEEEKIkaIkTQghhBgpStKEEEKIkaIkTQghhBgpStKEEEKIkaIkTQghhBgpStKEEEKIkaIkTQghhBip/wfjS2+dwITZlAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "81bf6244-5443-4de6-8e15-04579cc7fb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A quick brown fox. Weve decided this is the safest place to hide it. . . . Weve just seen him yet! said Hermione, looking through the crowd. We\n"
     ]
    }
   ],
   "source": [
    "start_context = \"A quick brown fox\"\n",
    "generate_and_print_sample(model_hp, tokenizer, device, start_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d7be13-a9d1-43c4-851a-c09b5fabacf1",
   "metadata": {},
   "source": [
    "## Decoding Strategies to Control Randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "30b2816f-f009-4827-99cd-6553d3c60cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model_verdict\n",
    "model = model_hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e51ad03e-5634-4f4e-9d77-8704c67a846f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "torch.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e0eb0539-67c8-4321-b912-e3c1e96133c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Text:\n",
      " I don't believe in the forest.\n",
      "Fair for hours, said Harry. I booked the field for a\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(model=model, idx=text_to_token_ids(\"I don't believe in\", tokenizer), max_new_tokens=25,\n",
    "                                context_size=GPT_CONFIG_124M[\"context_length\"])\n",
    "print(\"Output Text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba5f233-c42b-4162-a505-802944cc3965",
   "metadata": {},
   "source": [
    "### Decoding Strategy 1: Temperature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf70f5fc-efb7-43d7-b7ac-2586a9b9cf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {\n",
    "    \"closer\": 0,\n",
    "    \"every\": 1,\n",
    "    \"effort\": 2,\n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5,\n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "    \n",
    "}\n",
    "\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4f7db2c-5600-4512-a188-93e65022e0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.9, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e1bfadf1-5bef-4c34-ae33-ef632a7e4db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    0.0609,     0.0016,     0.0001,     0.5721,     0.0034,     0.0001,\n",
      "            0.0001,     0.3576,     0.0040])\n",
      "3\n",
      "forward\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(next_token_logits, dim=-1)\n",
    "print(probas)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "print(next_token_id)\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "012055ac-f3a5-4ebc-be72-c85bf94bd98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7c08dc5d-8e57-4aa9-910c-d546922abc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 x closer\n",
      "2 x every\n",
      "0 x effort\n",
      "544 x forward\n",
      "2 x inches\n",
      "1 x moves\n",
      "0 x pizza\n",
      "376 x toward\n",
      "4 x you\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123)\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
    "    sample_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i, freq in enumerate(sample_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9e69d117-bd5e-497e-839c-9644c56a3f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)\n",
    "\n",
    "# Temperature values\n",
    "temperature = [1, 0.1, 5] # Original, higher confidence, lower confidence\n",
    "\n",
    "# Calculate scaled probabilities\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bb9eb9b1-d7ad-47c6-a392-f99f2d5bf00a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "for i, T in enumerate(temperature):\n",
    "    rects = ax.bar(x+i*bar_width, scaled_probas[i], bar_width, label=f'Temperature = {T}')\n",
    "\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "37bc4345-64aa-4c8b-a607-8cb1d54557c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    0.0000,     0.0000,     0.0000,     0.9910,     0.0000,     0.0000,\n",
      "            0.0000,     0.0090,     0.0000])\n"
     ]
    }
   ],
   "source": [
    "# Probabilities when temperature is 0.1 -- Low randomness/creativity\n",
    "next_token_logits_2 = next_token_logits / 0.1\n",
    "probas_2 = torch.softmax(next_token_logits_2, dim=-1)\n",
    "print(probas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9802c0c5-7e17-4a3e-b051-8704ec1e0950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1546, 0.0750, 0.0429, 0.2421, 0.0869, 0.0454, 0.0430, 0.2203, 0.0898])\n"
     ]
    }
   ],
   "source": [
    "# Probabilities when temperature is 5 -- High randomness/creativity\n",
    "next_token_logits_3 = next_token_logits / 5\n",
    "probas_3 = torch.softmax(next_token_logits_3, dim=-1)\n",
    "print(probas_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6ead58-6581-418b-9bd4-f925ccbb9205",
   "metadata": {},
   "source": [
    "### Decoding Strategy 2: Top-k Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "53732d71-6ba9-463b-811c-3fdd4df8a5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.9, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2da39cde-a72c-407d-9d3d-24e8ac48d469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top Positions: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "print(\"Top logits:\", top_logits)\n",
    "print(\"Top Positions:\", top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "db707fbf-34b4-4ba0-9728-fc6f36aadcb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(condition=next_token_logits < top_logits[-1],\n",
    "                        input=torch.tensor(float(\"-inf\")),\n",
    "                        other=next_token_logits)\n",
    "\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "786b97d2-83ae-42d3-9eac-d5a3f8945962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "topk_probas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5724f5-ddb1-4dce-bf09-ab562fbc0959",
   "metadata": {},
   "source": [
    "### Merge Temperature Scaling and Top-k Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ff27008b-0e96-44c5-ae46-d324955aea7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # New: Filter logits with top_k sampling\n",
    "        if top_k is not None:\n",
    "            # Keep only top_k values\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "\n",
    "        # New: Apply temperature scaling\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # Apply softmax to get probabilities\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "\n",
    "            # Sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "\n",
    "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
    "            break\n",
    "\n",
    "        # Same as before: append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b332950c-3cbf-496b-825b-a2a75e951641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you have left this happen today, would I not! She giggles\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=60,\n",
    "    temperature=1.5\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94044170-40bb-4781-9402-ce7b2345cab6",
   "metadata": {},
   "source": [
    "## Loading and Saving Model Weights In Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "97cca282-dc4e-4bfd-818a-d69150b7f51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_hp.state_dict(), \"model_hp.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f14667d0-4d5b-4391-be33-e0a50aae7426",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zeeshan\\AppData\\Local\\Temp\\ipykernel_2312\\3721523108.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"model_hp.pth\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(torch.load(\"model_hp.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2b73ad46-1430-4e69-a905-a20627247c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you have left this happen today, would I not! She giggles\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=30,\n",
    "    temperature=1.5\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3028da-dc7c-453e-9aa5-126e5592c158",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
